{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c9c5a6",
   "metadata": {},
   "source": [
    "\n",
    "   ### Do temp gen fix and img (8)\n",
    "    ## - train on img_rand test on fix_rand\n",
    "    ## - train on img_radn test on fix_det\n",
    "    ## - train on img_det test on fix_rand\n",
    "    ## - train on img_det test on fix_det\n",
    "    \n",
    "    ## - train on fix_rand test on img_rand\n",
    "    ## - train on fix_radn test on img_det\n",
    "    ## - train on fix_det test on img_rand\n",
    "    ## - train on fix_det test on img_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea7e2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from sklearn.discriminant_analysis import _cov\n",
    "import scipy\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_data(file):\n",
    "   \n",
    "    print('loading file: ' + file)\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    return(data)\n",
    "\n",
    "def dump_data(data, filename):\n",
    "    print('writing file: ' + filename)\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def subsample_data(dat, sub_factor):\n",
    "    dshape = dat['eeg'].shape\n",
    "    sub_ix = list(range(0, dshape[-1], sub_factor))\n",
    "    dat['eeg'] = dat['eeg'][:,:,sub_ix]\n",
    "    dat['time'] = dat['time'][sub_ix]\n",
    "    \n",
    "    return dat\n",
    "    \n",
    "\n",
    "def get_pseudotrials(eeg_dat, tr_num):\n",
    "    \"\"\"\n",
    "    Applies pseudotrial creation independently for each slice of the first leading dimension.\n",
    "    \n",
    "    Parameters:\n",
    "        eeg_dat (numpy.ndarray): EEG data with shape (2, 4, 150, 64, 90).\n",
    "        tr_num (int): Desired number of trials.\n",
    "    \n",
    "    Returns:\n",
    "        pst (numpy.ndarray): Pseudotrials with shape (2, 4, tr_num, 64, 90).\n",
    "        k (int): Number of chunks each trial is divided into.\n",
    "    \"\"\"\n",
    "    # Prepare to store results\n",
    "    results = []\n",
    "    k_values = []\n",
    "\n",
    "    # Iterate over the first leading dimension\n",
    "    for i in range(eeg_dat.shape[0]):\n",
    "        single_data = eeg_dat[i]  # Extract slice with shape (4, 150, 64, 90)\n",
    "        \n",
    "        shape = single_data.shape\n",
    "        k = shape[1]  # Start with the number of trials\n",
    "        l = int(shape[1] / k)\n",
    "        \n",
    "        # Adjust k and l to fit tr_num\n",
    "        while l < int(tr_num):\n",
    "            k = k - 1\n",
    "            l = int(shape[1] / k)\n",
    "\n",
    "        # Shuffle and reshape for pseudotrials\n",
    "        single_data = single_data[:, np.random.permutation(shape[1]), :, :]\n",
    "        single_data = single_data[:, :l*k, :, :]\n",
    "        single_data = single_data.reshape(shape[0], k, l, shape[2], shape[3])\n",
    "        \n",
    "        # Average across the pseudotrial axis\n",
    "        pst_single = single_data.mean(axis=1)  # Resulting shape: (4, l, 64, 90)\n",
    "\n",
    "        results.append(pst_single)  # Append results for this slice\n",
    "        k_values.append(k)\n",
    "\n",
    "    # Stack results along the first axis to combine (2, 4, l, 64, 90)\n",
    "    pst = np.stack(results, axis=0)\n",
    "    k = k_values[0]  # Assuming k is the same across all slices\n",
    "    \n",
    "    return pst, k\n",
    "\n",
    "\n",
    "def average_across_points(dat, window_size=10):\n",
    "    dshape = dat['eeg'].shape\n",
    "    \n",
    "    new_length = dshape[-1] // window_size\n",
    "    eeg_reshaped = dat['eeg'][:, :, :new_length * window_size].reshape(dshape[0], dshape[1], new_length, window_size)\n",
    "    dat['eeg'] = eeg_reshaped.mean(axis=-1)\n",
    "    dat['time'] = dat['time'][:new_length * window_size].reshape(new_length, window_size).mean(axis=-1)\n",
    "    \n",
    "    return dat\n",
    "\n",
    "def select_partition(data, cond):\n",
    "    \n",
    "    ### Select condition \n",
    "    image_labels = [1,2,3,4]\n",
    "    if cond == \"rand\":\n",
    "        image_labels = [im + 10 for im in image_labels]\n",
    "\n",
    "    mask = np.isin(data[\"ids\"], image_labels)\n",
    "\n",
    "    eeg = data[\"eeg\"][mask]\n",
    "    ids = data[\"ids\"][mask]\n",
    "    return eeg, ids\n",
    "\n",
    "def random_eeg_pick(eeg, ids):\n",
    "    eeg_svm = np.full((len((np.unique(ids))), trial_lim, eeg.shape[1], eeg.shape[2]), np.nan)\n",
    "    for idx, x in enumerate(np.unique(ids)):\n",
    "        \n",
    "        total_num_trials = len(ids[ids == x])\n",
    "        range_array = np.arange(0, total_num_trials)\n",
    "        random_numbers = np.random.choice(range_array, trial_lim, replace=False)\n",
    "        # Select\n",
    "        eeg_svm[idx, :, :, :] = eeg[ids == x][random_numbers, :, :]\n",
    "        \n",
    "    return eeg_svm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79db060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: fix_det, Testing on: img_det\n",
      "loading file: /projects/crunchie/boyanova/EEG_Things/eeg_experiment/eeg_epoched/eeg_things_0005_fix.pickle\n",
      "loading file: /projects/crunchie/boyanova/EEG_Things/eeg_experiment/eeg_epoched/eeg_things_0005_img.pickle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1f1672f2d44fb8acc67ac6a6c16932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv: 1, out of: 6\n",
      "cv: 2, out of: 6\n",
      "cv: 3, out of: 6\n",
      "cv: 4, out of: 6\n",
      "cv: 5, out of: 6\n",
      "cv: 6, out of: 6\n",
      "cv: 1, out of: 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-09a318310360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mtt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                                 \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                                 \u001b[0macc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                                 \u001b[0;31m# we store the acc score in the temp gen mattrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                                 \u001b[0mTG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/crunchie/boyanova/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 with config_context(\n\u001b[0m\u001b[1;32m    207\u001b[0m                     skip_parameter_validation=(\n\u001b[1;32m    208\u001b[0m                         \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/crunchie/boyanova/anaconda3/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_GeneratorContextManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/crunchie/boyanova/anaconda3/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, args, kwds)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Issue 19330: ensure context manager instances have good docstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__doc__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Load Data\n",
    "\n",
    "\n",
    "subsample_factor = 10\n",
    "testsize = 0.2\n",
    "trial_num = 12\n",
    "img_nperms = 25\n",
    "trial_lim = 150\n",
    "\n",
    "decoding_data = {}\n",
    "\n",
    "pairs = [(\"fix_det\", \"img_det\"),\n",
    "         (\"fix_rand\", \"img_rand\"),\n",
    "         (\"img_det\", \"fix_det\"),\n",
    "         (\"img_rand\", \"fix_rand\")]\n",
    "\n",
    "for pair_train, pair_test in pairs:\n",
    "    print(f\"Training on: {pair_train}, Testing on: {pair_test}\")\n",
    "    cond_name = f\"{pair_train}_{pair_test}\"\n",
    "    train_out = pair_train.split(\"_\")[0]\n",
    "    train_in = pair_train.split(\"_\")[1]\n",
    "    \n",
    "    test_out = pair_test.split(\"_\")[0]\n",
    "    test_in = pair_test.split(\"_\")[1]\n",
    "    \n",
    "    if train_out != test_out:\n",
    "        dat_name = f\"/projects/crunchie/boyanova/EEG_Things/eeg_experiment/eeg_epoched/eeg_things_{sub:04d}_{train_out}.pickle\"\n",
    "        dat_train = load_data(dat_name)\n",
    "        \n",
    "        ### Subsample data\n",
    "        dat_train = average_across_points(dat_train, window_size=10)\n",
    "\n",
    "        ### Button press mask\n",
    "        bt_press = dat_train[\"button_press_mask\"]\n",
    "        dat_train[\"eeg\"] = dat_train[\"eeg\"][~bt_press]\n",
    "        dat_train[\"ids\"] = dat_train[\"ids\"][~bt_press]\n",
    "        dat_train[\"block_num\"] = dat_train[\"block_num\"][~bt_press]\n",
    "        \n",
    "        dat_name = f\"/projects/crunchie/boyanova/EEG_Things/eeg_experiment/eeg_epoched/eeg_things_{sub:04d}_{test_out}.pickle\"\n",
    "        dat_test = load_data(dat_name)\n",
    "        \n",
    "        ### Subsample data\n",
    "        dat_test = average_across_points(dat_test, window_size=10)\n",
    "\n",
    "        ### Button press mask\n",
    "        bt_press = dat_test[\"button_press_mask\"]\n",
    "        dat_test[\"eeg\"] = dat_test[\"eeg\"][~bt_press]\n",
    "        dat_test[\"ids\"] = dat_test[\"ids\"][~bt_press]\n",
    "        dat_test[\"block_num\"] = dat_test[\"block_num\"][~bt_press]        \n",
    "        \n",
    "        ### Get vars\n",
    "        n_conditions = len(range(4))\n",
    "        n_sensors = dat_train[\"eeg\"].shape[1]\n",
    "        n_time = dat_train[\"eeg\"].shape[-1]\n",
    "\n",
    "        ### DA matrix \n",
    "        TG = np.full((n_conditions, n_conditions, n_time, n_time), np.nan)        \n",
    "        train_eeg, train_ids = select_partition(dat_train, train_in)\n",
    "        test_eeg, test_ids = select_partition(dat_test, test_in)\n",
    "          \n",
    "        for p in tqdm(range(img_nperms)):\n",
    "            eeg_svm_train = random_eeg_pick(train_eeg, train_ids)\n",
    "            eeg_svm_test = random_eeg_pick(test_eeg, test_ids)\n",
    "\n",
    "            eeg_general = np.stack((eeg_svm_train, eeg_svm_test), axis=0)\n",
    "            pstrials, binsize = get_pseudotrials(eeg_general, trial_num)\n",
    "           \n",
    "            n_pstrials = pstrials.shape[2]\n",
    "            n_test = int(n_pstrials * testsize)\n",
    "            ps_ixs = np.arange(n_pstrials)\n",
    "            cvs = int(n_pstrials / n_test)\n",
    "\n",
    "            for cv in range(cvs):\n",
    "                print('cv: {}, out of: {}'.format(cv+1, cvs))\n",
    "\n",
    "                # we take idxs for the test/train\n",
    "                test_ix = np.arange(n_test) + (cv * n_test)\n",
    "                train_ix = np.delete(ps_ixs.copy(), test_ix)\n",
    "\n",
    "                # subset idxs from the pseudotrials\n",
    "                ps_train = pstrials[0]\n",
    "                ps_test = pstrials[1]\n",
    "                ps_train = ps_train[:,train_ix,:,:]\n",
    "                ps_test = ps_test[:,test_ix,:,:]\n",
    "\n",
    "                sigma_ = np.empty((n_conditions, n_sensors, n_sensors))\n",
    "                for c in range(n_conditions):\n",
    "                    # compute sigma for each time point, then average across time\n",
    "                    sigma_[c] = np.mean([_cov(ps_train[c, :, :, t], shrinkage='auto')\n",
    "                                        for t in range(n_time)], axis=0)\n",
    "                \n",
    "                # average across conditions\n",
    "                sigma = sigma_.mean(axis=0)  \n",
    "                # the formula is sigma * -1/2 // reason for sigma_inv\n",
    "                sigma_inv = scipy.linalg.fractional_matrix_power(sigma, -0.5)\n",
    "\n",
    "                # apply sigma to pseudo trials \n",
    "                ps_train = (ps_train.swapaxes(2, 3) @ sigma_inv).swapaxes(2, 3)\n",
    "                ps_test = (ps_test.swapaxes(2, 3) @ sigma_inv).swapaxes(2, 3)\n",
    "\n",
    "                # decoding: cA image vs cB (cA + 1 :) // then do it for each time point \n",
    "                for cA in range(n_conditions):\n",
    "                    #print('decoding image ' + str(cA))\n",
    "                    for cB in range(cA+1, n_conditions):\n",
    "                        for t in range(n_time):\n",
    "                            # retrieve the patterns from pseudotrials that correspond to cA and cB at time pt t\n",
    "                            train_x = np.array((ps_train[cA,:,:,t], ps_train[cB,:,:,t]))\n",
    "                            # concatinate them\n",
    "                            train_x = np.reshape(train_x,(len(train_ix)*2, n_sensors))\n",
    "                            # do the same with the test set, but here we take all time points \n",
    "                            test_x = np.array((ps_test[cA], ps_test[cB]))\n",
    "                            test_x = np.reshape(test_x,(len(test_ix)*2, n_sensors, n_time))\n",
    "                            # config labesls 1 for cA and 2 for cB\n",
    "                            train_y = np.array([1] * len(train_ix) + [2] * len(train_ix))\n",
    "                            test_y = np.array([1] * len(test_ix) + [2] * len(test_ix))\n",
    "\n",
    "                            # instantiate a classifier \n",
    "                            classifier = LinearSVC(dual=True,\n",
    "                                                    penalty = 'l2',\n",
    "                                                    loss = 'hinge',\n",
    "                                                    C = .5,\n",
    "                                                    multi_class = 'ovr',\n",
    "                                                    fit_intercept = True,\n",
    "                                                    max_iter = 10000)\n",
    "                            # train it\n",
    "                            classifier.fit(train_x, train_y)\n",
    "                            for tt in range(n_time):\n",
    "                                pred_y = classifier.predict(test_x[:,:,tt])\n",
    "                                acc_score = accuracy_score(test_y,pred_y)\n",
    "                                # we store the acc score in the temp gen mattrix \n",
    "                                TG[cA,cB,t,tt] = np.nansum(np.array((TG[cA,cB,t,tt],acc_score)))\n",
    "        TG = TG / (img_nperms * cvs)\n",
    "        decoding_data[cond_name] = TG\n",
    "        \n",
    "dump_data(decoding_data, \"/projects/crunchie/boyanova/EEG_Things/eeg_experiment/eeg_decoding/eeg_TG_between_att_{:04d}.pickle\".format(sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529faf41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
