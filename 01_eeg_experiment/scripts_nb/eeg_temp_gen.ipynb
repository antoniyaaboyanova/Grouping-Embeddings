{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c9c5a6",
   "metadata": {},
   "source": [
    "### Do temp gen within condition (4)\n",
    "    ## - fix_rand\n",
    "    ## - fix_det\n",
    "    ## - img_rand\n",
    "    ## - img_rand\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7e2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from sklearn.discriminant_analysis import _cov\n",
    "import scipy\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_data(file):\n",
    "   \n",
    "    print('loading file: ' + file)\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    return(data)\n",
    "\n",
    "def dump_data(data, filename):\n",
    "    print('writing file: ' + filename)\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def subsample_data(dat, sub_factor):\n",
    "    dshape = dat['eeg'].shape\n",
    "    sub_ix = list(range(0, dshape[-1], sub_factor))\n",
    "    dat['eeg'] = dat['eeg'][:,:,sub_ix]\n",
    "    dat['time'] = dat['time'][sub_ix]\n",
    "    \n",
    "    return dat\n",
    "    \n",
    "def get_pseudotrials(eeg_dat, tr_num):\n",
    "    shape = eeg_dat.shape\n",
    "    k = shape[1]\n",
    "    l = int(shape[1] / k)\n",
    "    \n",
    "    while l < int(tr_num):\n",
    "        k = k - 1\n",
    "        l = int(shape[1] / k)\n",
    "\n",
    "    eeg_dat = eeg_dat[:,np.random.permutation(shape[1]),:,:]\n",
    "    eeg_dat = eeg_dat[:,:l*k,:,:]\n",
    "\n",
    "    pst = np.reshape(eeg_dat, (shape[0], k, l, shape[2],shape[3]))\n",
    "    pst = pst.mean(axis=1)\n",
    "\n",
    "    return(pst, k)\n",
    "\n",
    "def average_across_points(dat, window_size=10):\n",
    "    dshape = dat['eeg'].shape\n",
    "    \n",
    "    new_length = dshape[-1] // window_size\n",
    "    eeg_reshaped = dat['eeg'][:, :, :new_length * window_size].reshape(dshape[0], dshape[1], new_length, window_size)\n",
    "    dat['eeg'] = eeg_reshaped.mean(axis=-1)\n",
    "    dat['time'] = dat['time'][:new_length * window_size].reshape(new_length, window_size).mean(axis=-1)\n",
    "    \n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240adbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fix_det\n",
      "loading file: /projects/crunchie/boyanova/EEG_Things/eeg_experiment/eeg_epoched/eeg_things_0005_fix.pickle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f705ed86f3e44ac9f64089cc0b44dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Load Data\n",
    "sub = 5\n",
    "conditions_1 = [\"fix\", \"img\"]\n",
    "conditions_2 = [\"det\", \"rand\"]\n",
    "subsample_factor = 10\n",
    "testsize = 0.2\n",
    "trial_num = 12\n",
    "img_nperms = 25\n",
    "trial_lim = 150\n",
    "\n",
    "decoding_data = {}\n",
    "\n",
    "for cond in conditions_1:\n",
    "    for cond2 in conditions_2:\n",
    "        cond_name = \"{}_{}\".format(cond, cond2)\n",
    "        decoding_data[cond_name] = []\n",
    "        \n",
    "        print(cond_name)\n",
    "        dat_name = \"/projects/crunchie/boyanova/EEG_Things/eeg_experiment/eeg_epoched/eeg_things_{:04d}_{}.pickle\".format(sub, cond)\n",
    "        dat = load_data(dat_name)\n",
    "\n",
    "        ### Subsample data\n",
    "        dat = average_across_points(dat, window_size=10)\n",
    "\n",
    "        \n",
    "        ### Button press mask\n",
    "        bt_press = dat[\"button_press_mask\"]\n",
    "        dat[\"eeg\"] = dat[\"eeg\"][~bt_press]\n",
    "        dat[\"ids\"] = dat[\"ids\"][~bt_press]\n",
    "        dat[\"block_num\"] = dat[\"block_num\"][~bt_press]\n",
    "\n",
    "        ### Select condition \n",
    "        image_labels = [1,2,3,4]\n",
    "        if cond2 == \"rand\":\n",
    "            image_labels = [im + 10 for im in image_labels]\n",
    "\n",
    "        mask = np.isin(dat[\"ids\"], image_labels)\n",
    "\n",
    "        eeg_ = dat[\"eeg\"][mask]\n",
    "        ids_ = dat[\"ids\"][mask]\n",
    "        blocks = dat[\"block_num\"][mask]\n",
    "        \n",
    "\n",
    "        ### Get vars\n",
    "        n_conditions = len(image_labels)\n",
    "        n_sensors = eeg_.shape[1]\n",
    "        n_time = eeg_.shape[-1]\n",
    "\n",
    "        # DA matrix \n",
    "        TG = np.full((n_conditions, n_conditions, n_time, n_time), np.nan)\n",
    "\n",
    "        ### Randomly pick 300 trials per conditoin  \n",
    "        eeg_svm = np.full((len((np.unique(ids_))), trial_lim, eeg_.shape[1], eeg_.shape[2]), np.nan)\n",
    "       \n",
    "\n",
    "        for p in tqdm(range(img_nperms)):\n",
    "            for idx, x in enumerate(np.unique(ids_)):\n",
    "                total_num_trials = len(ids_[ids_ == x])\n",
    "\n",
    "                # Define the range\n",
    "                range_array = np.arange(0, total_num_trials)\n",
    "\n",
    "                # Pick x random idx without repetition\n",
    "                random_numbers = np.random.choice(range_array, trial_lim, replace=False)\n",
    "\n",
    "                # Select\n",
    "                eeg_svm[idx, :, :, :] = eeg_[ids_== x][random_numbers, :, :]\n",
    "\n",
    "\n",
    "            pstrials, binsize = get_pseudotrials(eeg_svm, trial_num)  \n",
    "            n_pstrials = pstrials.shape[1]\n",
    "            n_test = int(n_pstrials * testsize)\n",
    "            #print(f'binsize: {binsize}, N of pstrials: {n_pstrials}, N sensors:{n_sensors}')\n",
    "\n",
    "            ps_ixs = np.arange(n_pstrials)\n",
    "            cvs = int(n_pstrials / n_test)\n",
    "\n",
    "            for cv in range(cvs):\n",
    "                #print('cv: {}, out of: {}'.format(cv+1, cvs))\n",
    "\n",
    "                # we take idxs for the test/train\n",
    "                test_ix = np.arange(n_test) + (cv * n_test)\n",
    "                train_ix = np.delete(ps_ixs.copy(), test_ix)\n",
    "\n",
    "                # subset idxs from the pseudotrials \n",
    "                ps_train = pstrials[:,train_ix,:,:]\n",
    "                ps_test = pstrials[:,test_ix,:,:]\n",
    "\n",
    "                # Whitening using the Epoch method // multivariate noise norm - it uses the cov b/w channels\n",
    "                # https://www.sciencedirect.com/science/article/abs/pii/S1053811918301411\n",
    "                # https://doi.org/10.1016/j.neuroimage.2015.12.012\n",
    "                sigma_ = np.empty((n_conditions, n_sensors, n_sensors))\n",
    "                for c in range(n_conditions):\n",
    "                    # compute sigma for each time point, then average across time\n",
    "                    sigma_[c] = np.mean([_cov(ps_train[c, :, :, t], shrinkage='auto')\n",
    "                                         for t in range(n_time)], axis=0)\n",
    "                sigma = sigma_.mean(axis=0)  # average across conditions\n",
    "                # the formula is sigma * -1/2 // reason for sigma_inv\n",
    "                sigma_inv = scipy.linalg.fractional_matrix_power(sigma, -0.5)\n",
    "\n",
    "                # apply sigma to pseudo trials \n",
    "                ps_train = (ps_train.swapaxes(2, 3) @ sigma_inv).swapaxes(2, 3)\n",
    "                ps_test = (ps_test.swapaxes(2, 3) @ sigma_inv).swapaxes(2, 3)\n",
    "                #print('Whitening done!')\n",
    "                #print('-' * 20)\n",
    "\n",
    "                #################\n",
    "                # decoding: cA image vs cB (cA + 1 :) // then do it for each time point \n",
    "                for cA in range(n_conditions):\n",
    "                    #print('decoding image ' + str(cA))\n",
    "                    for cB in range(cA+1, n_conditions):\n",
    "                        for t in range(n_time):\n",
    "                            # retrieve the patterns from pseudotrials that correspond to cA and cB at time pt t\n",
    "                            train_x = np.array((ps_train[cA,:,:,t], ps_train[cB,:,:,t]))\n",
    "                            # concatinate them\n",
    "                            train_x = np.reshape(train_x,(len(train_ix)*2, n_sensors))\n",
    "                            # do the same with the test set, but here we take all time points \n",
    "                            test_x = np.array((ps_test[cA], ps_test[cB]))\n",
    "                            test_x = np.reshape(test_x,(len(test_ix)*2, n_sensors, n_time))\n",
    "                            # config labesls 1 for cA and 2 for cB\n",
    "                            train_y = np.array([1] * len(train_ix) + [2] * len(train_ix))\n",
    "                            test_y = np.array([1] * len(test_ix) + [2] * len(test_ix))\n",
    "\n",
    "                            # instantiate a classifier \n",
    "                            classifier = LinearSVC(dual=True,\n",
    "                                                    penalty = 'l2',\n",
    "                                                    loss = 'hinge',\n",
    "                                                    C = .5,\n",
    "                                                    multi_class = 'ovr',\n",
    "                                                    fit_intercept = True,\n",
    "                                                    max_iter = 10000)\n",
    "                            # train it\n",
    "                            classifier.fit(train_x, train_y)\n",
    "                            for tt in range(n_time):\n",
    "                                pred_y = classifier.predict(test_x[:,:,tt])\n",
    "                                acc_score = accuracy_score(test_y,pred_y)\n",
    "                                # we store the acc score in the temp gen mattrix \n",
    "                                TG[cA,cB,t,tt] = np.nansum(np.array((TG[cA,cB,t,tt],acc_score)))\n",
    "\n",
    "\n",
    "\n",
    "        TG = TG / (img_nperms * cvs)\n",
    "        decoding_data[cond_name] = TG\n",
    "        \n",
    "dump_data(decoding_data, \"/projects/crunchie/boyanova/EEG_Things/eeg_experiment/eeg_decoding/eeg_TG_within_{:04d}.pickle\".format(sub))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
